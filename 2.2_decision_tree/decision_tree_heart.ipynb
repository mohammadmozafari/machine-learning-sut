{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248d47b6",
   "metadata": {},
   "source": [
    "**FILL THIS SECTION BY YOUR NAME AND STUDENT CODE** : \n",
    "\n",
    "- NAME : Mohammad Mozafari (محمد مظفری)\n",
    "- STUDENT CODE : 400201167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5feaada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "# IMPORT MORE MODULES IF YOU WANT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6345e1",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3590571",
   "metadata": {},
   "source": [
    "Read the dataset in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7248c704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "0        0   0     1  \n",
       "1        0   0     2  \n",
       "2        2   0     2  \n",
       "3        2   0     2  \n",
       "4        2   0     2  \n",
       "..     ...  ..   ...  \n",
       "298      1   0     3  \n",
       "299      1   0     3  \n",
       "300      1   2     3  \n",
       "301      1   1     3  \n",
       "302      1   1     2  \n",
       "\n",
       "[303 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/heart.csv')\n",
    "X = df.loc[:, df.columns != 'target']\n",
    "y = df['target']\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c1c685",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a6a064",
   "metadata": {},
   "source": [
    "First of all, search for missing values in the dataset. if there are missing values, handle them however you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ad824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 0\n"
     ]
    }
   ],
   "source": [
    "num_missing = df.isnull().sum().sum()\n",
    "print('Number of missing values:', num_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d75210",
   "metadata": {},
   "source": [
    "Then, read the dataset catalog. There are some categorical features with the \"int\" type. Encode these features so that you can distinguish between numerical and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25de8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My implementation doesn't require this step. All data, categorical or continuous, are treated the same way. In fact if there's any categorical data (with any type other than \"int\") it must be converted to a numeric value so that we can use it in our algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac80b358",
   "metadata": {},
   "source": [
    "### Declare feature vector and target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd380b7b",
   "metadata": {},
   "source": [
    "Here, you are supposed to convert pandas data frame into feature vectors and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc35fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a17a0",
   "metadata": {},
   "source": [
    "### Split data into separate training and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25fd9b6",
   "metadata": {},
   "source": [
    "Now it's time to split X and y into separate training and test set. You can use the sklearn library for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dacf4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fraction = 0.8\n",
    "num_total = X.shape[0]\n",
    "num_train = int(num_total * split_fraction)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6555b74",
   "metadata": {},
   "source": [
    "## Implement desicion tree algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339be89",
   "metadata": {},
   "source": [
    "In this cell, you are going to implement your decision tree. Feel free to add more arguments to functions or add your desired functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b689aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "     \n",
    "    def __init__(self, criterion=\"entropy\", max_depth=None, depth=0, min_points=1):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        \n",
    "        criterion -- “gini” for the Gini impurity and “entropy” for the information gain. (default “entropy”)\n",
    "        max_depth -- The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure. (default=None)\n",
    "        \"\"\"\n",
    "        # FILL HERE\n",
    "        self.max_depth = float('inf') if (max_depth is None) else max_depth\n",
    "        self.min_points = min_points\n",
    "        self.left_tree = None\n",
    "        self.right_tree = None\n",
    "        self.depth = depth\n",
    "        self.leaf = False\n",
    "        self.label = None\n",
    "        self.split_condition = (None, None)\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def compute_gini(self, data):\n",
    "        result = 1\n",
    "        total = len(data)\n",
    "        counter = Counter(data)\n",
    "        for value in counter.values():\n",
    "            result -= (value/total) ** 2\n",
    "        return result\n",
    "\n",
    "    def compute_entropy(self, data):\n",
    "        result = 0\n",
    "        total = len(data)\n",
    "        counter = Counter(data)\n",
    "        for value in counter.values():\n",
    "            p = (value/total)\n",
    "            result -= p * math.log2(p)\n",
    "        return result\n",
    "\n",
    "    def compute_gain(self, root_data, left_data, right_data):\n",
    "        c1, c2, c3 = 0, 0, 0\n",
    "        if self.criterion == 'entropy':\n",
    "            c1 = self.compute_entropy(root_data)\n",
    "            c2 = self.compute_entropy(left_data)\n",
    "            c3 = self.compute_entropy(right_data)\n",
    "        else:\n",
    "            c1 = self.compute_gini(root_data)\n",
    "            c2 = self.compute_gini(left_data)\n",
    "            c3 = self.compute_gini(right_data)\n",
    "        m = len(left_data)\n",
    "        n = len(right_data)\n",
    "        return (c1 - (m/(m+n)) * c2 - (n/(m+n)) * c3)\n",
    "\n",
    "    def get_avgs(self, numbers):\n",
    "        numbers = np.sort(numbers)\n",
    "        return np.convolve(numbers, np.ones(2)) / 2\n",
    "\n",
    "    def find_best_split_condition(self, X, y):\n",
    "        data = np.concatenate((X, y.reshape(-1, 1)), axis=1)\n",
    "        max_gain = 0\n",
    "        bfeature, bvalue = None, None\n",
    "        for feature in range(X.shape[1]):\n",
    "            values = self.get_avgs(X[:, feature])\n",
    "            for value in values:\n",
    "                y_left = data[data[:, feature] <= value, -1]\n",
    "                y_right = data[data[:, feature] > value, -1]\n",
    "                gain = self.compute_gain(data[:, -1], y_left, y_right)\n",
    "                if gain > max_gain:\n",
    "                    max_gain = gain\n",
    "                    bfeature, bvalue = feature, value\n",
    "        return bfeature, bvalue\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Build a decision tree classifier from the training set (X, y).\n",
    "\n",
    "        Returns:\n",
    "        self : Fitted estimator\n",
    "        \"\"\"\n",
    "        data = np.concatenate((X, y.reshape(-1, 1)), axis=1)\n",
    "        if (X.shape[0] > self.min_points) and (self.depth < self.max_depth):\n",
    "            bfeature, bvalue = self.find_best_split_condition(X, y)\n",
    "            if (bfeature is not None) and (bvalue is not None):\n",
    "                self.split_condition = (bfeature, bvalue)   \n",
    "                data_left = data[data[:, bfeature] <= bvalue]\n",
    "                data_right = data[data[:, bfeature] > bvalue]\n",
    "                self.left = DecisionTree(criterion=self.criterion, max_depth=self.max_depth, depth=self.depth + 1, min_points=self.min_points)\n",
    "                self.right = DecisionTree(criterion=self.criterion, max_depth=self.max_depth, depth=self.depth + 1, min_points=self.min_points)\n",
    "                self.left.fit(data_left[:, :-1], data_left[:, -1])\n",
    "                self.right.fit(data_right[:, :-1], data_right[:, -1])\n",
    "            else:\n",
    "                self.leaf = True\n",
    "                counter = Counter(y)\n",
    "                self.label = max(counter, key=counter.get)\n",
    "        else:\n",
    "            self.leaf = True\n",
    "            counter = Counter(y)\n",
    "            self.label = max(counter, key=counter.get)\n",
    "        return self\n",
    "    \n",
    "    def predict_single(self, x):\n",
    "        if self.leaf:\n",
    "            return self.label\n",
    "        if x[self.split_condition[0]] <= self.split_condition[1]:\n",
    "            return self.left.predict_single(x)\n",
    "        else:\n",
    "            return self.right.predict_single(x)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class value for X.\n",
    "\n",
    "        Returns:\n",
    "        y : The predicted classes\n",
    "        \"\"\"\n",
    "        y = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            pred = self.predict_single(X[i])\n",
    "            y[i] = pred   \n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c267b831",
   "metadata": {},
   "source": [
    "### Part 1 : Compare Gini and Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "511ec5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_gini = DecisionTree(criterion='gini',)\n",
    "dt_entropy = DecisionTree(criterion='entropy',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb1f0ac",
   "metadata": {},
   "source": [
    "In this cell, fit both declared trees on the train set and predict values on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "826f7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(model1, model2, X_train, y_train, X_test):\n",
    "    model1.fit(X_train, y_train)\n",
    "    model2.fit(X_train, y_train)\n",
    "    preds1 = model1.predict(X_test)\n",
    "    preds2 = model2.predict(X_test)\n",
    "    return preds1, preds2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ecdffe",
   "metadata": {},
   "source": [
    "Plot confusion matrix for both decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0948f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(targets, preds):\n",
    "    num_data = targets.shape[0]\n",
    "    accuracy = np.sum(targets == preds) / num_data\n",
    "    return accuracy\n",
    "\n",
    "def compute_confusion_matrix(targets, preds):\n",
    "    TP = np.sum(targets * preds)\n",
    "    FP = np.sum((1-targets) * preds)\n",
    "    TN = np.sum((1-targets) * (1-targets))\n",
    "    FN = np.sum(targets * (1-preds))\n",
    "    return TP, FP, TN, FN\n",
    "\n",
    "def report_classification(targets, preds):\n",
    "    accuracy = compute_accuracy(targets, preds)\n",
    "    TP, FP, TN, FN = compute_confusion_matrix(targets, preds)\n",
    "    precision = TP/(TP + FP)\n",
    "    recall = TP/(TP + FN)\n",
    "    specificity = TN/(TN + FP)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return accuracy, precision, recall, specificity, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a895cd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Accuracy, Precision, Recall, Specificity, F1)\n",
      "Gini results:\n",
      "\tOn training data:\n",
      "\t\t(1.0, 1.0, 1.0, 1.0, 1.0)\n",
      "\tOn test data:\n",
      "\t\t(0.7704918032786885, 0.8108108108108109, 0.8108108108108109, 0.7741935483870968, 0.8108108108108109)\n",
      "Entropy results:\n",
      "\tOn training data:\n",
      "\t\t(1.0, 1.0, 1.0, 1.0, 1.0)\n",
      "\tOn test data:\n",
      "\t\t(0.7049180327868853, 0.7567567567567568, 0.7567567567567568, 0.7272727272727273, 0.7567567567567567)\n"
     ]
    }
   ],
   "source": [
    "gini_preds, entropy_preds = fit_and_predict(dt_gini, dt_entropy, X_train, y_train, X_train)\n",
    "gini_report_train = report_classification(y_train, gini_preds)\n",
    "entropy_report_train = report_classification(y_train, entropy_preds)\n",
    "\n",
    "gini_preds, entropy_preds = fit_and_predict(dt_gini, dt_entropy, X_train, y_train, X_test)\n",
    "gini_report_test = report_classification(y_test, gini_preds)\n",
    "entropy_report_test = report_classification(y_test, entropy_preds)\n",
    "\n",
    "print('(Accuracy, Precision, Recall, Specificity, F1)')\n",
    "print('Gini results:')\n",
    "print('\\tOn training data:')\n",
    "print('\\t\\t{}'.format(gini_report_train))\n",
    "print('\\tOn test data:')\n",
    "print('\\t\\t{}'.format(gini_report_test))\n",
    "\n",
    "print('Entropy results:')\n",
    "print('\\tOn training data:')\n",
    "print('\\t\\t{}'.format(entropy_report_train))\n",
    "print('\\tOn test data:')\n",
    "print('\\t\\t{}'.format(entropy_report_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e9f01f",
   "metadata": {},
   "source": [
    "### Part 2 : Let's add maximum depth!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b7033",
   "metadata": {},
   "source": [
    "Define an array of different maximum depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6934e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "max_depths = [2, 5, 7, 10, 15, 20] # FILL THIS LIST WITH DESIRED VALUES\n",
    "accuracy_scores = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    dt = DecisionTree(criterion='gini',max_depth=max_depth) # Feel free to change the \"entropy\" to the \"gini\"\n",
    "    # dt = tree.DecisionTreeClassifier(criterion='gini', max_depth=max_depth)\n",
    "    dt.fit(X_train, y_train)\n",
    "    test_preds = dt.predict(X_test)\n",
    "    train_preds = dt.predict(X_train)\n",
    "    test_report = report_classification(y_test, test_preds)\n",
    "    train_report = report_classification(y_train, train_preds)\n",
    "    \n",
    "    # FIT declared tree to the train set and predict values on the test set. then calcualte accuracy score on the test set\n",
    "    # Feel free to use the sklearn moudle for calcualting accuracy score.\n",
    "    accuracy_score = test_report[0]\n",
    "    accuracy_scores.append(accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8f43ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth : 2, Accuracy : 0.7540983606557377\n",
      "Depth : 5, Accuracy : 0.8032786885245902\n",
      "Depth : 7, Accuracy : 0.7704918032786885\n",
      "Depth : 10, Accuracy : 0.7704918032786885\n",
      "Depth : 15, Accuracy : 0.7704918032786885\n",
      "Depth : 20, Accuracy : 0.7704918032786885\n"
     ]
    }
   ],
   "source": [
    "for depth, score in zip(max_depths, accuracy_scores):\n",
    "    print(f\"Depth : {depth}, Accuracy : {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e81c1d",
   "metadata": {},
   "source": [
    "Now compare the accuracy score of decision trees with and without using the \"max_depth\" parameter and discuss the effects of limiting the maximum depth of decision trees.\n",
    "\n",
    "Answer: When using \"max_depth\" the accuracy on train data will decrease but this allows more generalization and prevents overfitting. But when we allow infinite depth, although our training accuracy reaches 100% but test accuracy will drop because of overfitting. So it's better to look at validation data and choose the maximum depth where validation accuracy is still increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fa1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "818dd9f29eb8b9f4176cac8618347dba68cc82d46fab8fe0c5b8851c320da5b0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('cs231n': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
