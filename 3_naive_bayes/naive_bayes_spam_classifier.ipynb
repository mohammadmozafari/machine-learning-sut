{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports and downloads** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mohammad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mohammad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reading and splitting data**\n",
    "Here we read the main csv file and split data randomly to train and validation datasets (80% training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.read_csv('train_test.csv')\n",
    "df_train, df_val = train_test_split(df_total, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing**\n",
    "Here we apply some preprocessing on our data to get better results in classification.\n",
    "Preprocessings include:\n",
    "- lowercasing all characters\n",
    "- tokenization\n",
    "- stemming the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    s = s.lower()                       # only use lowercase characters\n",
    "    s = ' '.join(s.split())             # remove extra whitespace\n",
    "    tokens = word_tokenize(s)           # tokenization\n",
    "    \n",
    "    # remove stopwords\n",
    "    # swords = stopwords.words('english')\n",
    "    # nonstop_tokens = []\n",
    "    # for token in tokens:\n",
    "    #     if token not in swords:\n",
    "    #         nonstop_tokens.append(token)\n",
    "    # tokens = nonstop_tokens\n",
    "\n",
    "    # remove punctuations\n",
    "    regexp_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = regexp_tokenizer.tokenize(' '.join(tokens))\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    final_tokens = [stemmer.stem(t) for t in tokens]\n",
    "\n",
    "    s = ' '.join(final_tokens)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show a sample text and its normalized form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: No drama Pls.i have had enough from you and family while i am struggling in the hot sun in a strange place.No reason why there should be an ego of not going 'IF NOT INVITED' when actually its necessity to go.wait for very serious reppurcussions.\n",
      "Normalized text: no drama pl i have had enough from you and famili while i am struggl in the hot sun in a strang place no reason whi there should be an ego of not go if not invit when actual it necess to go wait for veri seriou reppurcuss\n"
     ]
    }
   ],
   "source": [
    "old_string = df_train.sample().iloc[0]['text']\n",
    "new_string = preprocess_string(old_string)\n",
    "print('Sample text:', old_string)\n",
    "print('Normalized text:', new_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    new_df = df.copy()\n",
    "    new_df['text'] = new_df['text'].apply(preprocess_string)\n",
    "    return new_df\n",
    "\n",
    "df_train = preprocess_data(df_train)\n",
    "df_val = preprocess_data(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training naive bayes parameters**\n",
    "For each email, the feature vector consists of all bigrams and unigrams present in that mail.\n",
    "Then we find the parameters of naive bayes classifier based on the training data.\n",
    "This is how we act:\n",
    "1. Loop through all emails.\n",
    "2. Count the number of all bigrams and unigrams in each class (spam and ham)\n",
    "3. Count the number of spam and ham emails (use it for prior probability)\n",
    "\n",
    "To determine the start and end of emails we use 2 special tokens: \"START\" and \"END\" \n",
    "\n",
    "So our feature vector for each email is basically a **vector that determines whether each bigram is present** in this instance or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bigrams = {'spam': 0, 'ham': 0}\n",
    "total_unigrams = {'spam': 0, 'ham': 0}\n",
    "bigram_counts = {'spam': {}, 'ham': {}}\n",
    "unigram_counts = {'spam': {}, 'ham': {}}\n",
    "num_spam = 0\n",
    "num_ham = 0\n",
    "vocab = {'<START>', '<END>'}\n",
    "\n",
    "for _, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    type = row['type']\n",
    "    tokens = word_tokenize(text)\n",
    "    if len(tokens) == 0:\n",
    "        continue\n",
    "    bigram_counts[type][('<START>', tokens[0])] = bigram_counts[type].get(('<START>', tokens[0]), 0) + 1\n",
    "    unigram_counts[type]['<START>'] = unigram_counts[type].get('<START>', 0) + 1\n",
    "    unigram_counts[type]['<END>'] = unigram_counts[type].get('<END>', 0) + 1\n",
    "    total_bigrams[type] += 1\n",
    "    total_unigrams[type] += 2\n",
    "    for i in range(len(tokens)):\n",
    "        unigram_counts[type][tokens[0]] = unigram_counts[type].get(tokens[0], 0) + 1\n",
    "        if i == len(tokens) - 1:\n",
    "            bigram_counts[type][(tokens[i], '<END>')] = bigram_counts[type].get((tokens[i], '<END>'), 0) + 1\n",
    "        else:\n",
    "            bigram_counts[type][(tokens[i], tokens[i+1])] = bigram_counts[type].get((tokens[i], tokens[i+1]), 0) + 1\n",
    "        total_bigrams[type] += 1\n",
    "        total_unigrams[type] += 1\n",
    "        vocab.add(tokens[i])\n",
    "    if type == 'spam':\n",
    "        num_spam += 1\n",
    "    else:\n",
    "        num_ham += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we visualize how this feature choosing can lead to good classifier. As it can be seen in the next 2 cells frequent bigrams in spam<br /> and non-spam messages could help detecting spam messages. This is the reason that we chose bigrams as our feature representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten most frequenc bigrams in spam messages\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('you', 'have'): 47,\n",
       " ('a', 'Ã¥'): 46,\n",
       " ('co', 'uk'): 41,\n",
       " ('<START>', 'you'): 40,\n",
       " ('to', 'claim'): 38,\n",
       " ('have', 'won'): 38,\n",
       " ('<START>', 'urgent'): 35,\n",
       " ('your', 'mobil'): 30,\n",
       " ('thi', 'is'): 29,\n",
       " ('pleas', 'call'): 29}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_spam = {k: v for k, v in sorted(bigram_counts['spam'].items(), key=lambda item: item[1])[-10:][::-1]}\n",
    "print('Top ten most frequenc bigrams in spam messages')\n",
    "freq_spam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten most frequenc bigrams in ham messages\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('<START>', 'i'): 397,\n",
       " ('i', 'm'): 271,\n",
       " ('n', 't'): 240,\n",
       " ('lt', 'gt'): 182,\n",
       " ('i', 'll'): 144,\n",
       " ('are', 'you'): 129,\n",
       " ('<START>', 'ok'): 106,\n",
       " ('i', 'am'): 104,\n",
       " ('have', 'a'): 93,\n",
       " ('do', 'n'): 91}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_ham = {k: v for k, v in sorted(bigram_counts['ham'].items(), key=lambda item: item[1])[-10:][::-1]}\n",
    "print('Top ten most frequenc bigrams in ham messages')\n",
    "freq_ham\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Validation**\n",
    "During inference we used the parameters calculated before to determine the probability of being spam or ham.\n",
    "<br />Then we report Accuracy, Precision, Recall on our validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability(tokens, bigrams, unigrams, prior, alpha):\n",
    "    prob = 0\n",
    "    prob += math.log((bigrams.get(('<START>', tokens[0]), 0) + alpha)/(unigrams.get('<START>', 0) + alpha * len(vocab)))\n",
    "    for i in range(len(tokens)):\n",
    "        if i == len(tokens) - 1:\n",
    "            prob += math.log((bigrams.get((tokens[i], '<END>'), 0) + alpha) / (\n",
    "                unigrams.get(tokens[i], 0) + alpha * len(vocab)))\n",
    "        else:\n",
    "            prob += math.log((bigrams.get((tokens[i], tokens[i+1]), 0) + alpha) / (\n",
    "                unigrams.get(tokens[i], 0) + alpha * len(vocab)))\n",
    "    prob += math.log(prior)\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.zeros(len(df_val))\n",
    "true_labels = ((df_val['type'] == 'spam') * 1).values\n",
    "\n",
    "i = 0\n",
    "for _, row in df_val.iterrows():\n",
    "    tokens = word_tokenize(row['text'])\n",
    "    if len(tokens) == 0:\n",
    "        continue\n",
    "    prob_spam = calculate_probability(tokens, bigram_counts['spam'], unigram_counts['spam'], num_spam/(num_spam + num_ham), 1)\n",
    "    prob_ham = calculate_probability(tokens, bigram_counts['ham'], unigram_counts['ham'], num_ham/(num_spam + num_ham), 1)\n",
    "    if prob_spam > prob_ham:\n",
    "        predicted_labels[i] = 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 0.8435374149659864\n",
      "Accuracy: 0.9773399014778326\n"
     ]
    }
   ],
   "source": [
    "TP = np.sum(predicted_labels * true_labels)\n",
    "FP = np.sum(predicted_labels * (1-true_labels))\n",
    "FN = np.sum((1-predicted_labels) * true_labels)\n",
    "TN = np.sum((1-predicted_labels) * (1-true_labels))\n",
    "\n",
    "precision = TP/(TP + FP)\n",
    "recall = TP/(TP + FN)\n",
    "accuracy = (TP + TN)/(TP + FP + TN + FN)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling overfitting** <br />\n",
    "3 cells back we defined a function called calculate_probability. This function takes a parameter called \"alpha\" as its input.<br />\n",
    "This parameter is used for smoothing. Without it if a given message has a bigram not seen before in training data it will assign 0 <br /> probability to that message which is unrealistic and indicates that our model has overfitted the training data. <br />\n",
    "So with this parameter we are doing some kind of regularization to increase our model's capability to generalize to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating output on test data**\n",
    "A file consisting of test data is given. <br />\n",
    "We compute our predictions on this test set and save the results in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('evaluate.csv')\n",
    "results = []\n",
    "for _, row in df_test.iterrows():\n",
    "    idx = row['id']\n",
    "    tokens = word_tokenize(preprocess_string(row['text']))\n",
    "    if len(tokens) == 0:\n",
    "        results.append((idx, 0))\n",
    "        continue\n",
    "    prob_spam = calculate_probability(\n",
    "        tokens, bigram_counts['spam'], unigram_counts['spam'], num_spam/(num_spam + num_ham))\n",
    "    prob_ham = calculate_probability(\n",
    "        tokens, bigram_counts['ham'], unigram_counts['ham'], num_ham/(num_spam + num_ham))\n",
    "    if prob_spam > prob_ham:\n",
    "        results.append((idx, 'spam'))\n",
    "    else:\n",
    "        results.append((idx, 'ham'))\n",
    "    \n",
    "df_results = pd.DataFrame(results, columns=['id', 'type'])\n",
    "df_results.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "818dd9f29eb8b9f4176cac8618347dba68cc82d46fab8fe0c5b8851c320da5b0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('cs231n': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
